{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce17a65c",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "0a0facdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38991eb",
   "metadata": {},
   "source": [
    "# Importando o dataset, renomeando coluna e split em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "179cd854",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Covid Data.csv')\n",
    "data = data.rename(columns = {'CLASIFFICATION_FINAL': 'CLASSIFICATION_FINAL'})\n",
    "data1 = data.copy()\n",
    "data1.loc[data1['DATE_DIED'] == '9999-99-99', 'DIED'] = 2\n",
    "data1.loc[data1['DATE_DIED'] != '9999-99-99', 'DIED'] = 1\n",
    "data1.drop(columns = ['DATE_DIED'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "1c3de399",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'DIED'\n",
    "features = list(set(data1.columns).difference({label}))\n",
    "X = data1[features]\n",
    "y = data1[label]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28000615",
   "metadata": {},
   "source": [
    "# Pré-Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "3eafde64",
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_features = ['PNEUMONIA', 'PREGNANT', 'DIABETES', 'COPD', 'ASTHMA', 'INMSUPR', 'HIPERTENSION',\n",
    "                   'CARDIOVASCULAR', 'RENAL_CHRONIC', 'OTHER_DISEASE', 'OBESITY', 'TOBACCO',\n",
    "                   'INTUBED', 'ICU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "72a4fdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_boolean_columns(data, boolean_features):\n",
    "    new_data = data.copy()\n",
    "    for feature in boolean_features:\n",
    "        new_data.loc[new_data[feature] < 3, f'is_{feature}_defined'] = 1\n",
    "        new_data.loc[new_data[feature] >= 3, f'is_{feature}_defined'] = 2\n",
    "    return new_data\n",
    "\n",
    "def correct_pregnant_for_men(data):\n",
    "    new_data = data.copy()\n",
    "    new_data.loc[new_data['SEX'] == 2, 'PREGNANT'] = 0\n",
    "    return new_data\n",
    "\n",
    "def mode_imputing(data, pre_imputing_train_data, boolean_features):\n",
    "    new_data = data.copy()\n",
    "    for feature in boolean_features:\n",
    "        most_common = pre_imputing_train_data[feature].mode()[0]\n",
    "        new_data.loc[new_data[feature] >= 3, feature] = most_common\n",
    "    return new_data\n",
    "\n",
    "def intubed_and_icu_imputing(data):\n",
    "    new_data = data.copy()\n",
    "    more_nan_features = ['INTUBED', 'ICU']\n",
    "    for feature in more_nan_features:\n",
    "        new_data.loc[new_data[feature] >= 3, feature] = 3\n",
    "    return new_data\n",
    "\n",
    "def covid_degree(data):\n",
    "    new_data = data.copy()\n",
    "    new_data.loc[new_data['CLASSIFICATION_FINAL'] >= 4, 'covid_degree'] = 0\n",
    "    new_data.loc[new_data['CLASSIFICATION_FINAL'] < 4, 'covid_degree'] = new_data['CLASSIFICATION_FINAL']\n",
    "    new_data.drop('CLASSIFICATION_FINAL', axis = 1, inplace = True)\n",
    "    return new_data\n",
    "\n",
    "def scale(feature, unscaled_train_feature):\n",
    "    minimum = min(unscaled_train_feature)\n",
    "    maximum = max(unscaled_train_feature)\n",
    "    return (feature - minimum)/(maximum - minimum)\n",
    "\n",
    "def binary_change(data):  \n",
    "    new_data = data.copy()\n",
    "    new_data.loc[new_data == 2] = 0\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "267ecd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing_pipeline(X_train, X_test, y_train, y_test, boolean_features):\n",
    "    X_train = create_boolean_columns(X_train, boolean_features)\n",
    "    X_test = create_boolean_columns(X_test, boolean_features)\n",
    "    \n",
    "    X_train = correct_pregnant_for_men(X_train)\n",
    "    X_test = correct_pregnant_for_men(X_test)\n",
    "    \n",
    "    pre_imputing_X_train = X_train.copy()\n",
    "    X_train = mode_imputing(X_train, pre_imputing_X_train, boolean_features)\n",
    "    X_test = mode_imputing(X_test, pre_imputing_X_train, boolean_features)\n",
    "    \n",
    "    X_train = intubed_and_icu_imputing(X_train)\n",
    "    X_test = intubed_and_icu_imputing(X_test)\n",
    "    \n",
    "    X_train = covid_degree(X_train)\n",
    "    X_test = covid_degree(X_test)\n",
    "    \n",
    "    features = X_train.columns\n",
    "    unscaled_X_train = X_train.copy()\n",
    "    \n",
    "    for feature in features:\n",
    "        X_train[feature] = scale(X_train[feature], unscaled_X_train[feature])\n",
    "        X_test[feature] = scale(X_test[feature], unscaled_X_train[feature])\n",
    "        \n",
    "    y_train = binary_change(y_train)\n",
    "    y_test = binary_change(y_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "e08680b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = pre_processing_pipeline(X_train, X_test, y_train, y_test, boolean_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "1a6f77b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "814d3f88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USMER</th>\n",
       "      <th>INMSUPR</th>\n",
       "      <th>INTUBED</th>\n",
       "      <th>ICU</th>\n",
       "      <th>COPD</th>\n",
       "      <th>PNEUMONIA</th>\n",
       "      <th>DIABETES</th>\n",
       "      <th>RENAL_CHRONIC</th>\n",
       "      <th>MEDICAL_UNIT</th>\n",
       "      <th>HIPERTENSION</th>\n",
       "      <th>...</th>\n",
       "      <th>is_INMSUPR_defined</th>\n",
       "      <th>is_HIPERTENSION_defined</th>\n",
       "      <th>is_CARDIOVASCULAR_defined</th>\n",
       "      <th>is_RENAL_CHRONIC_defined</th>\n",
       "      <th>is_OTHER_DISEASE_defined</th>\n",
       "      <th>is_OBESITY_defined</th>\n",
       "      <th>is_TOBACCO_defined</th>\n",
       "      <th>is_INTUBED_defined</th>\n",
       "      <th>is_ICU_defined</th>\n",
       "      <th>covid_degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>592908</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184386</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021782</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59606</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         USMER  INMSUPR  INTUBED  ICU  COPD  PNEUMONIA  DIABETES  \\\n",
       "592908     0.0      1.0      1.0  1.0   1.0        1.0       0.0   \n",
       "184386     1.0      1.0      1.0  1.0   1.0        1.0       1.0   \n",
       "1021782    1.0      1.0      1.0  1.0   1.0        1.0       1.0   \n",
       "59606      0.0      1.0      1.0  1.0   1.0        1.0       1.0   \n",
       "93792      0.0      1.0      0.5  0.5   1.0        1.0       0.0   \n",
       "\n",
       "         RENAL_CHRONIC  MEDICAL_UNIT  HIPERTENSION  ...  is_INMSUPR_defined  \\\n",
       "592908             1.0      0.916667           1.0  ...                 0.0   \n",
       "184386             1.0      0.250000           0.0  ...                 0.0   \n",
       "1021782            1.0      0.916667           1.0  ...                 0.0   \n",
       "59606              1.0      0.250000           1.0  ...                 0.0   \n",
       "93792              1.0      0.250000           1.0  ...                 0.0   \n",
       "\n",
       "         is_HIPERTENSION_defined  is_CARDIOVASCULAR_defined  \\\n",
       "592908                       0.0                        0.0   \n",
       "184386                       0.0                        0.0   \n",
       "1021782                      0.0                        0.0   \n",
       "59606                        0.0                        0.0   \n",
       "93792                        0.0                        0.0   \n",
       "\n",
       "         is_RENAL_CHRONIC_defined  is_OTHER_DISEASE_defined  \\\n",
       "592908                        0.0                       0.0   \n",
       "184386                        0.0                       0.0   \n",
       "1021782                       0.0                       0.0   \n",
       "59606                         0.0                       0.0   \n",
       "93792                         0.0                       0.0   \n",
       "\n",
       "         is_OBESITY_defined  is_TOBACCO_defined  is_INTUBED_defined  \\\n",
       "592908                  0.0                 0.0                 1.0   \n",
       "184386                  0.0                 0.0                 1.0   \n",
       "1021782                 0.0                 0.0                 1.0   \n",
       "59606                   0.0                 0.0                 1.0   \n",
       "93792                   0.0                 0.0                 0.0   \n",
       "\n",
       "         is_ICU_defined  covid_degree  \n",
       "592908              1.0           1.0  \n",
       "184386              1.0           0.0  \n",
       "1021782             1.0           0.0  \n",
       "59606               1.0           1.0  \n",
       "93792               0.0           1.0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "27378be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "592908     0.0\n",
       "184386     0.0\n",
       "1021782    0.0\n",
       "59606      0.0\n",
       "93792      0.0\n",
       "Name: DIED, dtype: float64"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e59804",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbe9828",
   "metadata": {},
   "source": [
    "A função de custo utilizada no modelo de regressão logística é a log loss:\n",
    "\n",
    "$$Log\\;Loss = -\\frac{1}{n}\\sum_{i = 1}^{n} y\\;log(\\hat{y}) + (1-y)\\;log(1-\\hat{y})$$\n",
    "\n",
    "sendo y a label do dataset de treino (0 ou 1) e $\\hat{y}$ o valor da label previsto pelo modelo (algo entre 0 e 1) para dados valores de features. O valor de $\\hat{y}$ é obtido pelo uso da função de ativação sigmoid em um modelo linear. Assim, definimos:\n",
    "\n",
    "$$z = b + \\sum_{i = 1}^{m} w_{i} x_{i}$$\n",
    "\n",
    "$$\\hat{y} = sigmoid(z) = sig(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "em que $w_{i}$ é o peso da feature $x_{i}$ no modelo.\n",
    "\n",
    "Nesse modelo, também aplicaremos a regularização $L_{1}$, responsável por levar os pesos de features pouco importantes (com pesos muito pequenos) a exatamente 0, realizando, assim, uma seleção de features que gera um modelo mais esparso. A função de regularização $L_{1}$ é dada por:\n",
    "\n",
    "$L_{1}\\;regularization\\;term = \\sum_{i = 1}^{m} |w_{i}|$\n",
    "\n",
    "Assim, a função que vamos querer minimizar é:\n",
    "\n",
    "$$f(\\theta) = Log\\;Loss + L_{1}\\;regularization\\;term = -\\frac{1}{n}\\sum_{i = 1}^{n} y_{i}\\;log(\\hat{y}_{i}) + (1-y_{i})\\;log(1-\\hat{y}_{i}) + \\lambda\\sum_{i = 1}^{m} |w_{i}|$$\n",
    "\n",
    "onde $\\lambda$ é a constante de regularização, $\\theta = (w_{1}, w_{2}, ..., w_{n}, b)$, sendo $n$ o número de linhas de dados que temos no dataset de treino e $m$ o número de features.\n",
    "\n",
    "Sabemos que: $\\frac{d\\hat{y}_{i}}{dz_{i}} = sig(z_{i}) \\cdot (1-sig(z_{i}))$ (verifique!)\n",
    "\n",
    "Assim, podemos calcular as derivadas parciais de $\\hat{y}_{i}$: \n",
    "\n",
    "$$\\frac{\\partial{\\hat{y}_{i}}}{\\partial{w_{k}}} = \\frac{d\\hat{y}_{i}}{dz_{i}} \\cdot \\frac{\\partial{z_{i}}}{\\partial{w_{k}}} = sig(z_{i})\\cdot(1-sig(z_{i}))\\cdot x_{k}$$\n",
    "\n",
    "para toda feature $x_{k}$, e:\n",
    "\n",
    "$$\\frac{\\partial{\\hat{y}_{i}}}{\\partial{b}} = \\frac{d\\hat{y}_{i}}{dz_{i}} \\cdot \\frac{\\partial{z_{i}}}{\\partial{b}} = sig(z_{i})\\cdot(1-sig(z_{i}))$$\n",
    "\n",
    "Calculando agora as derivadas parciais de $f(\\theta)$:\n",
    "\n",
    "$$\\frac{\\partial{f}}{\\partial{w_{k}}} = -\\frac{1}{n}\\sum_{i = 1}^{n}\\left[y_{i}\\cdot \\frac{sig(z_{i})\\cdot(1-sig(z_{i}))\\cdot (x_{k})_{i}}{\\hat{y}_{i}} - (1-y_{i})\\cdot\\frac{sig(z_{i})\\cdot(1-sig(z_{i}))\\cdot (x_{k})_{i}}{(1-\\hat{y}_{i})}\\right] + \\lambda \\frac{|w_{k}|}{w_{k}}$$\n",
    "\n",
    "$$\\frac{\\partial{f}}{\\partial{b}} = -\\frac{1}{n}\\sum_{i = 1}^{n}\\left[y_{i}\\cdot \\frac{sig(z_{i})\\cdot(1-sig(z_{i}))}{\\hat{y}_{i}} - (1-y_{i})\\cdot\\frac{sig(z_{i})\\cdot(1-sig(z_{i}))}{(1-\\hat{y}_{i})}\\right]$$\n",
    "\n",
    "Assim, sendo $\\alpha$ a taxa de aprendizado do modelo, os novos valores dos pesos e do viés serão:\n",
    "\n",
    "$$w_{k}' = w_{k} - \\alpha \\frac{\\partial{f}}{\\partial{w_{k}}}$$\n",
    "\n",
    "$$b' = b - \\alpha \\frac{\\partial{f}}{\\partial{b}}$$\n",
    "\n",
    "Desenvolvendo, temos, por fim:\n",
    "\n",
    "$$w_{k}' = w_{k} + \\frac{\\alpha}{n}\\sum_{i = 1}^{n}(x_{k})_{i}\\cdot\\left[y_{i}\\cdot {(1-\\hat{y}_{i})} - (1-y_{i})\\cdot \\hat{y}_{i}\\right] - \\alpha \\lambda \\frac{|w_{k}|}{w_{k}}$$\n",
    "\n",
    "$$b' = b + \\frac{\\alpha}{n}\\sum_{i = 1}^{n}\\left[y_{i}\\cdot {(1-\\hat{y}_{i})} - (1-y_{i})\\cdot \\hat{y}_{i}\\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b38776",
   "metadata": {},
   "source": [
    "# Implementação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "8544fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic_Regression():\n",
    "    def __init__(self, X_train, y_train, ws: list,\n",
    "                 b = 0, alpha = 0.1, lambda_reg = 0.1, random_state = 0):\n",
    "        self.features = X_train\n",
    "        self.label = y_train\n",
    "        for i in range(0, len(ws)):\n",
    "            ws[i] = float(ws[i])\n",
    "        self.ws = np.array(ws) # weights\n",
    "        self.b = b\n",
    "        self.alpha = alpha\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.rand = np.random.RandomState(random_state)\n",
    "        \n",
    "    def print_parameters(self):\n",
    "        for i in range(1, len(self.ws) + 1):\n",
    "            print(f'w{i} = {self.ws[i - 1]}')\n",
    "        print (f'b = {self.b}')\n",
    "        \n",
    "    def get_parameters(self):\n",
    "        i_vals = list(range(1, len(self.ws) + 1))\n",
    "        parameters = {f'w{i}': self.ws[i - 1] for i in i_vals}\n",
    "        parameters['b'] = self.b\n",
    "        return parameters\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(z):\n",
    "        return 1/(1 + np.exp(-z))\n",
    "    \n",
    "    def get_single_prediction(self, xs: list):\n",
    "        '''Get the prediction for a list with all the features' values.'''\n",
    "        for i in range(0, len(xs)):\n",
    "            xs[i] = float(xs[i])\n",
    "        xs = np.array(xs)\n",
    "        z = np.dot(self.ws, xs) + self.b\n",
    "        prediction = Logistic_Regression.sigmoid(z)\n",
    "        return prediction\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        n = len(X_test)\n",
    "        X_test_copy = X_test.copy()\n",
    "        X_test_copy.reset_index(inplace = True, drop = True)\n",
    "        k = 0\n",
    "        w_cols = []\n",
    "        for col in X_test_copy.columns:\n",
    "            X_test_copy.loc[0:n-1, f'weighted_{col}'] = self.ws[k]*X_test_copy[col]\n",
    "            w_cols.append(f'weighted_{col}')\n",
    "            k += 1\n",
    "        X_test_copy['Dot'] = X_test_copy[w_cols].sum(axis = 1)\n",
    "        X_test_copy['z'] = X_test_copy['Dot'] + self.b\n",
    "        X_test_copy.loc[0:n-1, 'Predictions'] = 1/(1 + np.exp(-X_test_copy['z']))\n",
    "        predictions = np.array(X_test_copy['Predictions'])\n",
    "        return predictions\n",
    "    \n",
    "    def get_loss(self, X_test, y_test):\n",
    "        n = len(X_test)\n",
    "        predictions = self.predict(X_test)\n",
    "        fst_term = np.dot(y_test, np.log(predictions))\n",
    "        sec_term = np.dot(1 - y_test, np.log(1 - predictions))\n",
    "        loss = -(1/n)*(fst_term + sec_term)\n",
    "        return loss\n",
    "    \n",
    "    def get_l1_term(self):\n",
    "        return np.sum(np.abs(self.ws))\n",
    "    \n",
    "    def get_structural_risk(self, X_test, y_test):\n",
    "        return self.get_loss(X_test, y_test) + self.lambda_reg * self.get_l1_term\n",
    "    \n",
    "    def sgd_update_parameters(self, batch_size: int):\n",
    "        n = len(self.label)\n",
    "        index_list = list(range(0, n))\n",
    "        random_indices = self.rand.choice(index_list, size = batch_size, replace = True) # bootstrap sample\n",
    "        xs_sample = list()\n",
    "        y_sample = np.array(self.label.iloc[random_indices])\n",
    "        preds_sample = np.zeros(batch_size)\n",
    "        for i in range(0, batch_size):\n",
    "            xs = list(self.features.iloc[random_indices[i]])\n",
    "            preds_sample[i] += self.get_single_prediction(xs)\n",
    "        for col in self.features:\n",
    "            xs_sample.append(np.array(self.features[col].iloc[random_indices])) # len(xs_sample) = len(self.ws)\n",
    "        partial_w = np.zeros(len(self.ws))\n",
    "        for k in range(0, len(self.ws)):\n",
    "            if self.ws[k] == 0:\n",
    "                partial_reg_term = 0\n",
    "            else:\n",
    "                partial_reg_term = np.abs(self.ws[k])/self.ws[k]\n",
    "            fst_term = (y_sample) * (1 - preds_sample)\n",
    "            sec_term = (1 - y_sample) * (preds_sample)\n",
    "            partial_w[k] += -(1/batch_size) * np.dot(xs_sample[k], fst_term - sec_term) + self.lambda_reg * partial_reg_term\n",
    "        partial_b = -(1/batch_size) * np.sum(fst_term - sec_term)\n",
    "        self.ws -= self.alpha * partial_w\n",
    "        self.b -= self.alpha * partial_b\n",
    "        \n",
    "    def sgd(self, iterations: int, batch_size: float, print_loss = False): # stochastic gradient descent\n",
    "        for i in range(0, iterations):\n",
    "            self.sgd_update_parameters(batch_size)\n",
    "            if print_loss:\n",
    "                print(f'loss = {self.get_loss(self.features, self.label)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "de36a6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = list(np.zeros(len(features)))\n",
    "model = Logistic_Regression(X_train = X_train, y_train = y_train, ws = ws, lambda_reg = 0.05, alpha = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "56086385",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.44959754569474175\n",
      "loss = 0.35680894940755653\n",
      "loss = 0.3169411413930308\n",
      "loss = 0.29838621222226314\n",
      "loss = 0.2765721215829366\n",
      "loss = 0.2717039086114165\n",
      "loss = 0.2580306466793227\n",
      "loss = 0.25067064653386195\n",
      "loss = 0.2454664350698992\n",
      "loss = 0.24182927054444495\n",
      "loss = 0.23946622298096598\n",
      "loss = 0.23766402293369632\n",
      "loss = 0.236645060760695\n",
      "loss = 0.23722821316904877\n",
      "loss = 0.2361099474849269\n",
      "loss = 0.23510364164027325\n",
      "loss = 0.23440350601537754\n",
      "loss = 0.2324461203275588\n",
      "loss = 0.2331542851234061\n",
      "loss = 0.2335351863325628\n",
      "loss = 0.23335221365252254\n",
      "loss = 0.2325670499613375\n",
      "loss = 0.2316148793098996\n",
      "loss = 0.23484770819623552\n",
      "loss = 0.2336953504597814\n",
      "loss = 0.23347468443863745\n",
      "loss = 0.2327363674447556\n",
      "loss = 0.2306857886386171\n",
      "loss = 0.22902112733454524\n",
      "loss = 0.22767427375550248\n",
      "loss = 0.2290536724222965\n",
      "loss = 0.2298482632883099\n",
      "loss = 0.2319992136201092\n",
      "loss = 0.23051457938386044\n",
      "loss = 0.23012800601585684\n",
      "loss = 0.2314292199872328\n",
      "loss = 0.23081272895655866\n",
      "loss = 0.2309988266968373\n",
      "loss = 0.22946752575313398\n",
      "loss = 0.2284791175742834\n"
     ]
    }
   ],
   "source": [
    "model.sgd(iterations = 40, batch_size = 100, print_loss = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "39950b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0914716 , 0.09653352, 0.08854787, ..., 0.0907446 , 0.10233488,\n",
       "       0.09145578])"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "0b040627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    193057\n",
       "1     16658\n",
       "dtype: int64"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.DataFrame(model.predict(X_test)) > 0.19).astype(int).value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
